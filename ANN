% Solve an Input-Output Fitting problem with a Neural Network
% Script generated by Neural Fitting app
% Created 08-Oct-2018 17:41:15
%
% This script assumes these variables are defined:
%
%   data - input data.
%   data - target data.
clc;
clear;
close all;
rng default
tic
%% check data without training
% filename1 = 'Case1_80%.xlsx';
% sheetname11 = 'Sheet11'; 
% sheetname22 = 'Sheet22';
% input11 = xlsread(filename1,sheetname11,'A1:Z40000'); 
% target11 = xlsread(filename1,sheetname22,'A1:Z40000');
% inputs11=input11';
% targets11=target11';
%%
% filename = 'ANN_ChuongDuong_04';
filename = 'Case1_beam_1.xlsx';
sheetname1 = 'Sheet1'; 
sheetname2 = 'Sheet2'; 
input = xlsread(filename,sheetname1,'A1:Z40000'); %call datas from sheetname1
target = xlsread(filename,sheetname2,'A1:Z40000'); %call datas from sheetname2
inputs=input'; 
targets=target';
x=inputs;
% x = awgn(inputs,100,'measured');
% x = awgn(inputs,100);
% plot(t,[x inputs])
% legend('Original Signal','Signal with AWGN')
% x=inputs;
t = targets;

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainscg';  % Levenberg-Marquardt backpropagation.
  
% Create a Fitting Network
hiddenLayerSize = 52;
% net = fitnet(hiddenLayerSize,trainFcn);
net=feedforwardnet(hiddenLayerSize,trainFcn); 

% Setup Division of Data for Training, Validation, Testing
% divideParam.trainRatio= 70/100;
% net.divideParam.trainRatio 
 net.divideParam.trainRatio =70/100;
net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 15/100;

%% net.trainParam
% net.divideFcn = '';
% net.trainParam.show = 50;
% net.trainParam.lr = 0.0001;
net.trainParam.epochs = 1000;
% net.trainParam.goal = 1e-5;
% net.trainParam.time=5;
% net.trainParam.showWindow=0
% net.trainParam.mu=0.005;
% net.trainParam
% %%
% net.trainFcn
% performFcn='mse';
% net.performFcn
% plotFcns={'plotperform', 'plottrainstate', 'plotfit'};
% net.plotFcns;
% net.plotParams;
% net.biasConnect
% net.inputConnect;
% net.layerConnect;
% net.outputConnect;
% net
% view(net);
% https://nl.mathworks.com/help/deeplearning/ref/traingd.html
%%
%Weight and bias
% Element_Target.ID=[1:1:10]';
% net.b{1,1}= 0.5.*ones(length(Element_Target.ID),1);
[net,tr] = train(net,x,t)
% net.IW{1,1}
% net.b{1,1}
%%init reinitializes those weight and bias values.
% net = init(net);
% net.IW{1,1}
% net.b{1,1}
%%
% Test the Network
y = net(x);
e = gsubtract(t,y);
% net=perform(net)
performance = perform(net,t,y)


% Test_ouputs1=net(x);
% Test_ouputs1 = [Test_ouputs1
%     targets];
% inputs3=[523];
% Test_ouputs3=net(inputs3)
% inputs4=[514];
% Test_ouputs4=net(inputs4)
% inputs5=[500];
% Test_ouputs5=net(inputs5)
% inputs3=[523; 1409; 2707];
% Test_ouputs3=net(inputs3)
% inputs4=[514; 1406; 2673];
% Test_ouputs4=net(inputs4)
% inputs5=[500; 1403; 2624];
% Test_ouputs5=net(inputs5)
%% test data including data without test
% Test_ouputs2=net(inputs11);
% Test_ouputs2 = [Test_ouputs2
%     targets11];
%%
nntraintool('plot','plotregression');
set(findall(gcf,'-property','FontSize'),'FontSize',10);
for i1 = 1:4
  subplot(2,2,i1)
  grid on
end
nntraintool('plot','plotperform');
set(findall(gcf,'-property','FontSize'),'FontSize',10);
grid on;
nntraintool('plot','plottrainstate');
set(findall(gcf,'-property','FontSize'),'FontSize',10);
grid on;
nntraintool('plot','ploterrhist');
set(findall(gcf,'-property','FontSize'),'FontSize',10);
grid on;
timeElapsed = toc

